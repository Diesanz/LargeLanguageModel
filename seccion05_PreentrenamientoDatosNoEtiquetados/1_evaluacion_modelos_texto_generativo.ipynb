{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b7ee1be",
   "metadata": {},
   "source": [
    "# Evaluación de modelos de texto generativo\n",
    "\n",
    "Se comenzará la sección configurando el LLM para la generación de texto a partir del código implementado en la sección 3.\n",
    "\n",
    "![Texto alternativo](./imgs/5.2.png)\n",
    "\n",
    "La  siguiente  subsección  resume  la  generación  de  texto  que se configuró al final de la sección 3, antes  de  sumergirnos  en  la  evaluación  del  texto  y  el  cálculo  \n",
    "de  las  pérdidas  de  entrenamiento  y  validación  en  las  subsecciones  posteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37007970",
   "metadata": {},
   "source": [
    "## Uso de GPT para generar texto\n",
    "\n",
    "En esta subsección se configura el LLm y se recapitula brevemente el proceso de generación de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d306ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Obtiene la ruta de la carpeta principal del proyecto (subiendo un nivel desde seccion05)\n",
    "ruta_proyecto_principal = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "# Añade esta ruta a la lista de lugares donde Python busca módulos\n",
    "if ruta_proyecto_principal not in sys.path:\n",
    "    sys.path.append(ruta_proyecto_principal)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c794100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vocab_size': 50257, 'context_length': 256, 'emb_dim': 768, 'n_heads': 12, 'n_layers': 12, 'drop_rate': 0.1, 'qkv_bias': False}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from seccion04_ImplementacionGPTGeneracionTexto.gptModel import GPTModel\n",
    "from seccion04_ImplementacionGPTGeneracionTexto.gptConfig124M import GPT_CONFIG_124M\n",
    "\n",
    "#importacion de librerias necesarias y acortamiento del context length de la configuracion de GPT (1024 tokens a  256)\n",
    "GPT_CONFIG_124M[\"context_length\"] = 256\n",
    "print(GPT_CONFIG_124M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb16f3bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7b2676",
   "metadata": {},
   "source": [
    "Esta  modificación  reduce  las  demandas  computacionales  del  entrenamiento  del  modelo,  haciendo  posible  realizar  el  entrenamiento  en  una  computadora  portátil  estándar.\n",
    "\n",
    "Originalmente,  el  modelo  GPT2,  con  124  millones  de  parámetros,  se  configuró  para  gestionar  hasta  1024  tokens. \n",
    "\n",
    "Utilizando  la  instancia  GPTmodel ,  adoptamos  la  función  generate_text_simple  presentada anteriorment e se introducen dos  funciones  útiles:  text_to_token_ids  y  token_ids_to_text.  Estas  funciones  facilitan  la  conversión  entre  representaciones  de  texto  y  tokens.\n",
    "\n",
    "![Texto alternativo](./imgs/5.3.png)\n",
    "\n",
    "- Primero,  el  tokenizador  convierte  el  texto  de  entrada  en  una  serie  de  identificadores  de  token.\n",
    "- Segundo,  el  modelo  recibe  estos  identificadores  de  token  y  genera  los  logits  correspondientes,  que  son  vectores  que  representan  la  distribución  de  probabilidad  de  cada  token  del  vocabulario.\n",
    "-  Tercero,  estos  logits  se  convierten  de  nuevo  en  identificadores  de  token,  que  el  tokenizador  decodifica  en  texto  legible,  completando  así  el  ciclo  de  entrada  a  salida  textual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "38383d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "from seccion04_ImplementacionGPTGeneracionTexto.generateTextSimple import generate_text_simple\n",
    "import tiktoken\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    # 1. squeeze(0): Quita la dimensión del \"lote\" que añadió unsqueeze.\n",
    "    #Es como sacar la lista de la caja para poder leerla.\n",
    "    #Ej: tensor([[25134]]) -> tensor([25134]), forma: [1]\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) \n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    # 2. Convierte el tensor 1D a una lista y luego a texto.\n",
    "    # Ej: tensor([25134]) -> [25134] -> \"hola\"\n",
    "\n",
    "    flat = token_ids.squeeze(0)\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8525554c",
   "metadata": {},
   "source": [
    "El modelo sigue sin producir texto coherente porque todavia no se ha entrenado.\n",
    "\n",
    "Para  definir  qué  hace  que  un  texto  sea  \"coherente\"  o  de  \"alta  calidad\", se debe implementar un  método  numérico  para  evaluar  el  contenido  generado.  Este  enfoque  nos  permitirá  monitorear  y  mejorar  el  rendimiento  del  modelo  durante  su  proceso  de  entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811a5af7",
   "metadata": {},
   "source": [
    "## Cálculo de la perdida de generación de texto\n",
    "\n",
    "En esta subsección se exploraran técnicas para evaluar numericamnte la calidad del texto generado durante el entrenamiento mediante el cálculo de la llamada función de pérdidda de generación de texto.\n",
    "\n",
    "![Texto alternativo](./imgs/5.1.png)\n",
    "\n",
    "Es necesario realizar todos estos pasos indicados en la figura antes de calcular una pérdida que mida la calidad de l texto generado.\n",
    "\n",
    "La figura describe  el  proceso  de  generación  de  texto  con  un  vocabulario  reducido  de  7  tokens  para  que  esta  imagen  quepa  en  una  sola  página.  Sin  embargo,  GPTModel  trabaja  con  un  vocabulario  mucho  mayor,  compuesto  por  50 257  palabras;  por  lo  tanto,  los  ID  de  token  en  los  siguientes  códigos  estarán  comprendidos  entre  0  y  50 256,  en  lugar  de  entre  0  y  6.\n",
    "\n",
    "Definición de dos entradas con sus objetivos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a662b89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paso 1\n",
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                        [40, 1107, 588]])   #  \"I really like\"]\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "                        [107,  588, 11311]]) #  \" really like chocolate\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eeee0d9",
   "metadata": {},
   "source": [
    "Los  objetivos  son  las  entradas,  pero  desplazados  una  posición  hacia  adelante.\n",
    "Esta  estrategia  de  desplazamiento  es  crucial  para  enseñar  al  modelo  a  predecir  el  siguiente  token  en  una  secuencia. Cuando  introducimos  las  entradas  en  el  modelo  para  calcular  vectores  logit  para  los  dos  ejemplos  de  entrada,  cada  uno  compuesto  por  tres  tokens,  y  aplicamos  la  función  softmax  para  transformar  estos  valores  logit  en  puntuaciones  de  probabilidad. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbe6e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n",
      "Ids token:  tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "source": [
    "#Paso 2: logits a scores de probabilidad\n",
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "print(probas.shape) \n",
    "#Paso 3 y 4: argmax para obtener el correspondiente token ID \n",
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Ids token: \", token_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84067cbb",
   "metadata": {},
   "source": [
    "Dado  que  se tiene  2  lotes  de  entrada,  cada  uno  con  3  tokens,  aplicar  la  función  argmax  a  los  puntajes  de  probabilidad  produce  2  conjuntos  de  salidas,  cada  uno  con  3  identificaciones  de  tokens  predichas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52b73d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "#Paso 5: Convertir IDs a texto\n",
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\") #verdadera salida\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\") #salida del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6f97d7",
   "metadata": {},
   "source": [
    "El  modelo  produce  texto  aleatorio  diferente  del  texto  objetivo  porque  aún  no  se  ha  entrenado. \n",
    "\n",
    "Ahora se debe evaluar numéricamente el rendimiento del texto generado por el modelo mediante la llamada pérdida. Esto no es solo útil para medir la calidad del texto generado, sino que también es un elemento fundamental para implementar posteriormente la función de entrenamiento, que se utiliza para actualizar el peso del modelo y mejorar el texto generado.\n",
    "\n",
    "![Texto alternativo](./imgs/5.5.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
