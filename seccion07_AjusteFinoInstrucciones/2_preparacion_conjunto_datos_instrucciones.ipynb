{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b078a8c",
   "metadata": {},
   "source": [
    "# Preparación de un conjunto de datos para el ajuste fino de instrucciones supervisadas\n",
    "\n",
    "En esta sección , se descargará y formateará un conjunto de datos de instrucciones pasra el ajuste fino de instrucciones de un LLM preentrenado.  El  conjunto  de  datos  consta  de  1100  pares  instrucción respuesta. \n",
    "\n",
    "El  siguiente  código  implementa  y  ejecuta  una  función para  descargar  este  conjunto  de  datos,  un  archivo  relativamente  pequeño  (solo  204  KB),  en  formato  JSON. JSON  (Notación  de  Objetos  JavaScript)  refleja  la  estructura  de  los  diccionarios  de  Python,  proporcionando  una  estructura  sencilla  para  el  intercambio  de  datos,  legible  tanto  para  humanos  como  para  máquinas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1472ea47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import urllib\n",
    "\n",
    "def download_and_load_file(file_path, url):\n",
    "    #Si no existe el archivo JSON descargado, se procede a su descarga\n",
    "    if not os.path.exists(file_path):\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "\n",
    "    #En este punto, el archivo ya existe: lo abrimos y cargamos su contenido JSON\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    return data\n",
    "\n",
    "file_path = \"instruction-data.json\"\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d45001e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example entry:\n",
      " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Example entry:\\n\", data[50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0654438",
   "metadata": {},
   "source": [
    "Las  entradas  de  ejemplo  son  objetos  de  diccionario  de  Python  que  contienen  una instrucción,  una  entrada  y  una  salida. \n",
    "\n",
    "En  función  del  contenido  de  esta  entrada,  es  posible  que  en  ocasiones  el  campo  'entrada' esté  vacío."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41c0ebd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Another example:\n",
      " {'instruction': \"What is an antonym of 'complicated'?\", 'input': '', 'output': \"An antonym of 'complicated' is 'simple'.\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Another example:\\n\", data[999])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c8d4da",
   "metadata": {},
   "source": [
    "El  ajuste  fino  de  instrucciones,  también  conocido  como  ajuste  fino  de  instrucciones  supervisadas,  implica  entrenar  un  modelo  en  un  conjunto  de  datos  donde  los  pares  de  entradasalida,  como  los  que  se extrageron  del  archivo  JSON,  se  proporcionan  explícitamente.  Existen  varios  métodos  para  formatear  estas  entradas  para  los  LLM.\n",
    "\n",
    "La  Figura  ilustra  dos  formatos  de  ejemplo  diferentes,  a  menudo  denominados  estilos  de  indicaciones,  utilizados  en  la  formación  de  importantes  LLM  como  Alpaca  y  Phi3.  Alpaca fue  uno  de  los  primeros  LLM  en  detallar  públicamente  su  proceso  de  ajuste  de  instrucción. Phi3,  desarrollado  por  Microsoft,  se  incluye  para  demostrar  la  diversidad  de  estilos  de  indicaciones\n",
    "\n",
    "![Texto alternativo](./imgs/7.4.png)\n",
    "\n",
    "El  resto  de  esta sección se utiliza  el  estilo  de  indicaciones  Alpaca,  ya  que  es  uno  de  los  más  populares,  en  gran  medida  porque  ayudó  a  definir  el  enfoque  original  del  ajuste  fino.\n",
    "\n",
    "Definir una función formar_input que se pueda usar para convertir las entradas de la lista de datos al formato de entrada estilo Alpaca.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ecb5aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb89c66",
   "metadata": {},
   "source": [
    "Esta  función  format_input  toma  una  entrada  de  diccionario  como  entrada  y  construye  una  cadena  formateada.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac2c1634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion\n",
      "\n",
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[50])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcaf4d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is an antonym of 'complicated'?\n",
      "\n",
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[999])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bae9e3",
   "metadata": {},
   "source": [
    "Como se puede ver la salida anterior, las entradas con un campo 'input' vacío no contienen una sección ###Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd5f7ff",
   "metadata": {},
   "source": [
    "Antes de configurar los cargadores de datos en Pytorch, se deve dividir el conjunto de datos en un conjunto de entrenamiento, validación y prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ed02b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Validation set length: 55\n",
      "Test set length: 110\n",
      "\n",
      "✅ Archivos guardados como JSON con pandas\n"
     ]
    }
   ],
   "source": [
    "#85% entrenamiento, 10% test y 5% validacion\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#Convertir la lista en DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calcular índices\n",
    "train_portion = int(len(df) * 0.85)\n",
    "test_portion = int(len(df) * 0.1)\n",
    "val_portion = len(df) - train_portion - test_portion\n",
    "\n",
    "#Divisiones\n",
    "train_df = df.iloc[:train_portion]\n",
    "test_df = df.iloc[train_portion:train_portion + test_portion]\n",
    "val_df = df.iloc[train_portion + test_portion:]\n",
    "\n",
    "#Mostrar tamaños\n",
    "print(\"Training set length:\", len(train_df))\n",
    "print(\"Validation set length:\", len(val_df))\n",
    "print(\"Test set length:\", len(test_df))\n",
    "\n",
    "#Guardar como JSON (o CSV si prefieres)\n",
    "train_df.to_json(\"train.json\", orient=\"records\", lines=False, force_ascii=False, indent=4)\n",
    "val_df.to_json(\"val.json\", orient=\"records\", lines=False, force_ascii=False, indent=4)\n",
    "test_df.to_json(\"test.json\", orient=\"records\", lines=False, force_ascii=False, indent=4)\n",
    "\n",
    "print(\"\\nArchivos guardados como JSON con pandas\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260233f4",
   "metadata": {},
   "source": [
    "Tras descargar y particionar el conjunto de datos, es momento de la implentación principal del proceso de ajuste fino de instrucciones.\n",
    "\n",
    "\n",
    "[Organización de datos en lotes de entrenamiento](./3_organizacion_datos_lotes_entrenamiento.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
