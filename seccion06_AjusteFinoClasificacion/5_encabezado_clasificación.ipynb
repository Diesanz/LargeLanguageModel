{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a750138",
   "metadata": {},
   "source": [
    "# Agregar un encabezado de clasificación\n",
    "\n",
    "Durante esta sección se modificará el modelo LLM preentrenado para prepararlo para el ajuste fino de la clasificación. Para ello se reemplaza la  capa  de  salida  original,  que  asigna  la  representación  oculta  a  un  vocabulario  de  50 257,  por  una  capa  de  salida  más  pequeña  que  asigna  dos  clases:  0  («no  spam»)  y  1  («spam»).\n",
    "\n",
    "![Texto alternativo](./imgs/6.8.png)\n",
    "\n",
    "Como se ve en la figura  se va a utilizar  el  mismo  modelo  que  en  las  secciones  anteriores  excepto  que  se reemplaza la  capa  de  salida.\n",
    "\n",
    "Técnicamente,  se podría  usar  un  solo  nodo  de  salida,  dado  que  se  trata  de  una  tarea  de  \n",
    "clasificación  binaria. Sin  embargo,  esto  requeriría  modificar  la  función  de  pérdida.\n",
    "Se opta por  un  enfoque  más  general  donde  el  número  de  nodos  de  salida  coincide  con  el  número  de  clases.  Por  ejemplo,  para  un  problema  de  tres  clases,  como  clasificar  artículos  de  noticias  como  \"Tecnología\",  \"Deportes\"  o  \"Política\",  se usarían tres  nodos  de  salida,  y  así  sucesivamete.\n",
    "\n",
    "Antes de modificar el modelo, se va a volver a cargar y a mostrar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "252ca861",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Obtiene la ruta de la carpeta principal del proyecto (subiendo un nivel desde seccion05)\n",
    "ruta_proyecto_principal = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "# Añade esta ruta a la lista de lugares donde Python busca módulos\n",
    "if ruta_proyecto_principal not in sys.path:\n",
    "    sys.path.append(ruta_proyecto_principal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72c44403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\checkpoint\n",
      "File already exists and is up-to-date: gpt2\\124M\\encoder.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\hparams.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2\\124M\\vocab.bpe\n",
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm()\n",
      "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from seccion05_PreentrenamientoDatosNoEtiquetados.gpt_download import download_and_load_gpt2\n",
    "from seccion05_PreentrenamientoDatosNoEtiquetados.loadWeightsGPTModels import load_weights_into_gpt\n",
    "from seccion04_ImplementacionGPTGeneracionTexto.gptModel import GPTModel\n",
    "#Reeutilizar configuraciones\n",
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90568071",
   "metadata": {},
   "source": [
    "El  GPTModel  consta  de  capas  de  incrustación,  seguidas  de  12  bloques  de  transformadores  idénticos,  seguidos  de  una  capa LayerNorm  final  y  la  capa  de  salida,  out_head."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d94ff2a",
   "metadata": {},
   "source": [
    "### AJUSTE  DE  CAPAS  SELECCIONADAS  FRENTE  A  TODAS  LAS  CAPAS\n",
    "Dado  que se parte de  un  modelo  preentrenado,  no  es  necesario  ajustar  todas  las  capas  del  modelo.  Esto  se  debe  a  que,  en  los  modelos  de  lenguaje  basados  en  redes  neuronales,  las  capas  inferiores  generalmente  capturan  las  estructuras  y  la  semántica  básicas  del  lenguaje,  aplicables  a  una  amplia  gama  de  tareas  y  conjuntos  de  datos.  Por  lo  tanto,  ajustar  solo  las  últimas  capas  (capas  cercanas  a  la  salida),  que  son  más  específicas  para  \n",
    "patrones  lingüísticos  con  matices  y  características  específicas  de  la  tarea,  suele  ser  suficiente  para  adaptar  el  modelo  a  nuevas  tareas.  Un  efecto  secundario  positivo  es  que  resulta  computacionalmente  más  eficiente  ajustar  solo  un  número  reducido  de  capas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8345f323",
   "metadata": {},
   "source": [
    "Para  preparar  el  modelo  para  el  ajuste  de  la  clasificación,  primero  se congela  el  modelo,  lo  que  significa  que  se hace  que  todas  las  capas  no  se  puedan  entrenar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea01aea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2364cd",
   "metadata": {},
   "source": [
    "Reemplazar la capa de salida (model.out_head), que  originalmente  asigna  las  entradas  de  la  capa  a  50,257  dimensiones  (el  tamaño  del  vocabulario):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "835e08e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(123)\n",
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear(\n",
    "    in_features=BASE_CONFIG[\"emb_dim\"],\n",
    "    out_features=num_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cb6424",
   "metadata": {},
   "source": [
    "Esta  nueva  capa  de  salida  model.out_head  tiene  su  atributo  requires_grad  establecido  en  Verdadero  de  manera  predeterminada,  lo  que  significa  que  es  la  única  capa  del  modelo  que  se  actualizará  durante  el  entrenamiento.\n",
    "\n",
    "Técnicamente,  entrenar  la  capa  de  salida  que  se acaba  de  añadir  es  suficiente.  Sin  embargo,  como se han descubierto en experimentos,  ajustar  capas  adicionales  puede  mejorar  notablemente  el  rendimiento  predictivo  del  modelo  ajustado. \n",
    "\n",
    "Además,  se configura el  último  bloque  transformador  y  el  módulo  final  LayerNorm ,que  conecta  este  bloque  a  la  capa  de  salida,  para  que  sea  entrenable.\n",
    "\n",
    "\n",
    "![Texto alternativo](./imgs/6.9.png)\n",
    "\n",
    "Para  hacer  que  el  último  bloque  LayerNorm  y  el  último  transformador  sean  entrenables,  se establecen  sus  respectivos  requires_grad  en  True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddf01f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.trf_blocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.final_norm.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98a8076",
   "metadata": {},
   "source": [
    "Aunque se añade una  nueva  capa  de  salida  y  se marcan  ciertas  capas  como  entrenables  o  no,  se puede usar  este  modelo  de  forma  similar  a  las secciones anteriores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80714fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: tensor([[5211,  345,  423,  640]])\n",
      "Inputs dimensions: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "inputs = tokenizer.encode(\"Do you have time\")\n",
    "inputs = torch.tensor(inputs).unsqueeze(0)\n",
    "print(\"Inputs:\", inputs)\n",
    "print(\"Inputs dimensions:\", inputs.shape) # shape: (batch_size, num_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3b6767",
   "metadata": {},
   "source": [
    "Como  lo  muestra  la  salida  de  impresión,  el  código  anterior  codifica  las  entradas  en  un  tensor  que  consta  de  4  tokens  de  entrada.\n",
    "\n",
    "Luego se pueden pasar los ID de token codificados al modelo como se ha hecho:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffded46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs:\n",
      " tensor([[[-0.5956, -0.0469],\n",
      "         [-0.4593, -0.5447],\n",
      "         [-0.1016,  0.5089],\n",
      "         [-0.0080, -0.4943]]])\n",
      "Outputs dimensions: torch.Size([1, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "print(\"Outputs:\\n\", outputs)\n",
    "print(\"Outputs dimensions:\", outputs.shape) #shape: (batch_size, num_tokens, num_classes)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa395c13",
   "metadata": {},
   "source": [
    "En secciones anteriores,  una  entrada  similar  habría  generado  un  tensor  de  salida  de  [1,  4,  50257],  donde  50257  representa  el  tamaño  del  vocabulario.  Al  igual  que  en  secciones anteiores,  el  número  de  filas  de  salida  corresponde  al  número  de  tokens  de  entrada  (en  este  caso,  4).  Sin  embargo,  la  dimensión  de  incrustación  de  cada  salida  (el  número  de  columnas)  se  ha  reducido  a  2  en  lugar  de  50257,  ya  que  se ha reemplazado  la  capa  de  salida  del  modelo.\n",
    "\n",
    "Solo interesa ajustar  este  modelo  para  que  devuelva  una  etiqueta  de  clase  que  indique  si  una  entrada  del  modelo  es  spam  o  no.  Para  lograrlo,  no se necesita ajustar las  cuatro  filas  de  salida,  sino  que se puede centrar  en  un  solo  token  de  salida.  En  particular,  hay que centrarse  en  la  última  fila  correspondiente  al  último  token  de  salida.\n",
    "\n",
    "![Texto alternativo](./imgs/6.10.png)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
