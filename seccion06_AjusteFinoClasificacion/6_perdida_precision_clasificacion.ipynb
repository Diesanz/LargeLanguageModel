{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "728f9249",
   "metadata": {},
   "source": [
    "# Cálculo de la pérdida y precisión de la clasificación\n",
    "\n",
    "Durante esta sección, se ha preparado un conjunto de datos, cargado un modelo preentrenado y modificado para el ajuste fino de la clasificación. ANtes de proceder con el ajuste fino, solo queda: implementar  las  funciones  de  evaluación  del  modelo  utilizadas  durante  el  ajuste  fino.\n",
    "\n",
    "![Texto alternativo](./imgs/6.12.png)\n",
    "\n",
    "Antes  de  implementar  las  utilidades  de  evaluación, hay que analizar  brevemente  cómo  se convierten  las  salidas  del  modelo  en  predicciones  de  etiquetas  de  clase.\n",
    "\n",
    "En  la sección 05,  se calculaba el  ID  del  siguiente  token  generado  por  el  LLM  convirtiendo  las  50 257  salidas  en  probabilidades  mediante  la  función  softmax  y  devolviendo  la  posición  de  mayor  probabilidad  mediante  la  función  argmax . En esta sección,  se utiliza el  mismo  enfoque  para  calcular  si  el  modelo  genera  una  predicción  de  \"spam\"  o  \"no  spam\"  para  una  entrada  dada,  con  la  única  diferencia  de  que  se trabaja  con  salidas  bidimensionales  en  lugar  de  50 257  dimensiones\n",
    "\n",
    "![Texto alternativo](./imgs/6.13.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9f1688b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Obtiene la ruta de la carpeta principal del proyecto (subiendo un nivel desde seccion05)\n",
    "ruta_proyecto_principal = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "# Añade esta ruta a la lista de lugares donde Python busca módulos\n",
    "if ruta_proyecto_principal not in sys.path:\n",
    "    sys.path.append(ruta_proyecto_principal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cda1ac45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\checkpoint\n",
      "File already exists and is up-to-date: gpt2\\124M\\encoder.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\hparams.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2\\124M\\vocab.bpe\n",
      "tensor([[-3.5983,  3.9902]])\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "import torch\n",
    "from gptModelClasification import return_clasification_model\n",
    "model = return_clasification_model()\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "inputs = tokenizer.encode(\"Do you have time\")\n",
    "inputs = torch.tensor(inputs).unsqueeze(0)\n",
    "with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "print(outputs[:,-1,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a277212",
   "metadata": {},
   "source": [
    "UNa vez obtenido los valores del tensor correspondiente al último token se puede obtener la etiqueta a traves de:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34d5c11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(outputs[:,-1,:], dim=-1)\n",
    "label = torch.argmax(probas)\n",
    "print(\"Class label:\", label.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161eaa05",
   "metadata": {},
   "source": [
    "En  este  caso,  el  código  devuelve  1,  lo  que  significa  que  el  modelo  predice  que  el  texto  de  entrada  es  \"spam\".\n",
    "El  uso  de  la  función  softmax  aquí  es  opcional  porque  los  resultados  más  grandes  corresponden  directamente  a  los  puntajes  de  probabilidad  más  altos.  Por  lo  tanto,  se puede simplificar  el  código  de  la  siguiente  manera,  sin  usar  softmax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dda2395d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "logits = outputs[:, -1, :]\n",
    "label = torch.argmax(logits)\n",
    "print(\"Class label:\", label.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df92ad7",
   "metadata": {},
   "source": [
    "Este  concepto  se  puede  utilizar  para  calcular  la  denominada  precisión  de  clasificación,  que  mide  el  porcentaje  de  predicciones  correctas  en  un  conjunto  de  datos.\n",
    "\n",
    "Para  determinar  la  precisión  de  la  clasificación,  se aplica  el  código  de  predicción  basado  en  argmax  a  todos  los  ejemplos  del  conjunto  de  datos  y  se calcula  la  proporción  de  predicciones  correctas  definiendo  una  función  calc_accuracy_loader :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "729de33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
    "    model.eval()\n",
    "    correct_predictions, num_examples = 0, 0\n",
    "\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    \n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "            with torch.no_grad():\n",
    "                logits = model(input_batch)[:, -1, :]             #logits del último token de cada batch\n",
    "            predicted_labels = torch.argmax(logits, dim=-1)\n",
    "            num_examples += predicted_labels.shape[0]\n",
    "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
    "        else:\n",
    "            break\n",
    "        return correct_predictions / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a02d3ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spamDataset import SpamDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 10\n",
    "train_dataset = SpamDataset(csv_file=\"CSV/train.csv\",max_length=None,tokenizer=tokenizer)\n",
    "val_dataset = SpamDataset(csv_file=\"CSV/validation.csv\",max_length=train_dataset.max_length,tokenizer=tokenizer)\n",
    "test_dataset = SpamDataset(csv_file=\"CSV/test.csv\",max_length=train_dataset.max_length,tokenizer=tokenizer)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "train_loader = DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True,num_workers=num_workers,drop_last=True,)\n",
    "val_loader = DataLoader(dataset=val_dataset,batch_size=batch_size,num_workers=num_workers,drop_last=False,)\n",
    "test_loader = DataLoader(dataset=test_dataset,batch_size=batch_size,num_workers=num_workers,drop_last=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eb85d847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 30.00%\n",
      "Validation accuracy: 50.00%\n",
      "Test accuracy: 60.00%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "torch.manual_seed(123)\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17f946c",
   "metadata": {},
   "source": [
    "Para mejorar el modelo es necesario realizar unos ajustes sobre el.\n",
    "Sin  embargo,  antes  de  comenzar  a  ajustar  el  modelo, se necesita definir  la  función  de  pérdida  que se optimizara durante  el  entrenamiento. El  objetivo  es  maximizar  la  precisión  de  la  clasificación  de  spam  del  modelo,  lo  que  significa  que  el  código  anterior  debe  generar  las  etiquetas  de  clase  correctas:  0  para  textos  que  no  son  spam  y  1  para  textos  spam.\n",
    "Sin  embargo,  la  precisión  de  la  clasificación  no  es  una  función  diferenciable,  por  lo  que  se utiliza  la  pérdida  de  entropía  cruzada  como  indicador  para  maximizar  la  precisión.  Esta  es  la  misma  pérdida  de  entropía  cruzada  que  se  analizó  en  la sección 05.\n",
    "En  consecuencia,  la  función  calc_loss_batch  sigue  siendo  la  misma  que  en  la sección  05,  con  un  ajuste:  hay que centrarse  en  optimizar  solo  el  último  token,  model(input_batch)[:,  1, :],  en  lugar  de  todos  los  tokens,  model(input_batch):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7c334127",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)[:,-1,:]\n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d652b43d",
   "metadata": {},
   "source": [
    "Calcular  la  pérdida  de  un  único  lote  obtenido  de  los  cargadores  de  datos  previamente  definidos.   Para  calcular  la  pérdida  de  todos  los  lotes  de  un  cargador  de  datos, se define  la  función  calc_loss_loader :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "63323a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:                                                      \n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c710d7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.474\n",
      "Validation loss: 2.688\n",
      "Test loss: 2.365\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():                                      \n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
    "print(f\"Training loss: {train_loss:.3f}\")\n",
    "print(f\"Validation loss: {val_loss:.3f}\")\n",
    "print(f\"Test loss: {test_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4da8d7",
   "metadata": {},
   "source": [
    "En la siguiente sección se implementará  una  función  de  entrenamiento  para  ajustar  el  modelo,  lo  que  implica  ajustarlo  para  minimizar  la  pérdida  del  conjunto  de  entrenamiento.  Minimizar  la  pérdida  del  conjunto  de  entrenamiento  ayudará  a  aumentar  la  precisión  de  la  clasificación,  al  objetivo  general.\n",
    "\n",
    "\n",
    "[Ajuste del modelo en datos supervisados](./7_ajuste_modelo_datos_supervisados.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
